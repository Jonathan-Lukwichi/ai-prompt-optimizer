"""
LUKTHAN - AI Prompt Agent
Transform rough ideas into powerful, optimized prompts
Specialized for Research and Coding workflows
"""
import streamlit as st
from datetime import datetime
from typing import Optional
from core.config import Config

# ==================== PAGE CONFIG ====================

st.set_page_config(
    page_title="LUKTHAN - AI Prompt Agent",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="collapsed",
    menu_items={
        'About': '# LUKTHAN - AI Prompt Agent\nStructured prompts for serious research and code.'
    }
)

# ==================== LOAD THEME ====================

from utils.chat_components import (
    load_lukthan_theme,
    render_welcome_hero,
    render_user_message,
    render_agent_response,
    render_insights_panel,
    render_file_indicator
)

load_lukthan_theme()

# ==================== API KEY CHECK ====================

if not Config.GEMINI_API_KEY or Config.GEMINI_API_KEY == "":
    st.error("""
    ### ‚ö†Ô∏è Configuration Required

    **Gemini API Key is not configured!**

    To use LUKTHAN:
    1. Get a FREE API key: https://makersuite.google.com/app/apikey
    2. Add to Streamlit Secrets: `GEMINI_API_KEY = "your-key"`
    """)
    st.stop()

# ==================== SESSION STATE ====================

if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

if 'uploaded_file_content' not in st.session_state:
    st.session_state.uploaded_file_content = None

if 'uploaded_file_type' not in st.session_state:
    st.session_state.uploaded_file_type = None

if 'uploaded_file_name' not in st.session_state:
    st.session_state.uploaded_file_name = None

if 'last_result' not in st.session_state:
    st.session_state.last_result = None

if 'pending_input' not in st.session_state:
    st.session_state.pending_input = None

if 'active_tab' not in st.session_state:
    st.session_state.active_tab = "Chat"

# ==================== HEADER WITH TABS ====================

# Brand header
col_brand, col_tabs, col_actions = st.columns([2, 4, 2])

with col_brand:
    st.markdown("### üß† LUKTHAN")

with col_tabs:
    # Tab navigation
    tab_chat, tab_settings = st.tabs(["üí¨ Chat", "‚öôÔ∏è Settings"])

with col_actions:
    if st.button("üóëÔ∏è Clear", use_container_width=True):
        st.session_state.chat_history = []
        st.session_state.uploaded_file_content = None
        st.session_state.uploaded_file_type = None
        st.session_state.uploaded_file_name = None
        st.session_state.last_result = None
        st.rerun()

st.divider()

# ==================== SETTINGS TAB ====================

with tab_settings:
    st.markdown("### ‚öôÔ∏è Agent Settings")

    col1, col2 = st.columns(2)

    with col1:
        st.selectbox(
            "Domain",
            ["üîÆ Auto Detect", "üî¨ Research", "üíª Coding", "üìä Data Science", "üåê General"],
            key="domain_setting"
        )
        st.selectbox(
            "Output Language",
            ["English", "French", "Spanish", "German", "Portuguese"],
            key="language_setting"
        )

    with col2:
        st.selectbox(
            "Target AI",
            ["ChatGPT (GPT-4)", "Claude 3.5", "Gemini Pro", "Llama 3"],
            key="target_ai_setting"
        )
        st.selectbox(
            "Expertise Level",
            ["Student", "Professional", "Expert", "Academic"],
            index=1,
            key="level_setting"
        )

    st.markdown("---")
    st.markdown("**üí° Tips:** Be specific ‚Ä¢ Include context ‚Ä¢ Mention output format")

# ==================== CHAT TAB ====================

with tab_chat:
    # Main layout: Chat + Insights
    chat_col, insights_col = st.columns([3, 2], gap="medium")

    # ==================== CHAT COLUMN ====================
    with chat_col:
        # Chat container
        chat_container = st.container()

        # Display chat history or welcome screen
        with chat_container:
            if not st.session_state.chat_history:
                # Show welcome hero with examples
                example_input = render_welcome_hero()
                if example_input:
                    st.session_state.pending_input = example_input
                    st.rerun()
            else:
                # Display chat messages
                for message in st.session_state.chat_history:
                    if message['role'] == 'user':
                        file_info = None
                        if message.get('file_name'):
                            file_info = {
                                'name': message['file_name'],
                                'type': message.get('file_type', 'unknown')
                            }
                        render_user_message(
                            message['content'],
                            message.get('timestamp'),
                            file_info
                        )
                    else:
                        action = render_agent_response(
                            prompt=message['prompt'],
                            domain=message.get('domain', 'general'),
                            task_type=message.get('task_type', 'general_query'),
                            quality_score=message.get('quality_score', 75),
                            suggestions=message.get('suggestions', [])
                        )
                        if action == "regenerate":
                            st.session_state.regenerate_last = True
                            st.rerun()

        # ==================== INPUT AREA ====================
        st.markdown("---")

        # File upload (inline)
        with st.expander("üìé Attach file", expanded=False):
            uploaded_file = st.file_uploader(
                "Upload",
                type=['pdf', 'txt', 'md', 'py', 'js', 'ts', 'java', 'cpp', 'go', 'rs', 'sql', 'json', 'yaml'],
                label_visibility="collapsed",
                key="file_uploader"
            )

            if uploaded_file:
                st.session_state.uploaded_file_name = uploaded_file.name
                try:
                    from core.file_processor import FileProcessor
                    processor = FileProcessor()
                    content, file_type = processor.process_file(uploaded_file)
                    st.session_state.uploaded_file_content = content
                    st.session_state.uploaded_file_type = file_type
                    st.success(f"üìÑ {uploaded_file.name}")
                except Exception as e:
                    st.error(f"Error: {str(e)}")

        # Text input
        default_value = ""
        if st.session_state.pending_input:
            default_value = st.session_state.pending_input
            st.session_state.pending_input = None

        user_input = st.text_area(
            "Prompt",
            value=default_value,
            placeholder="Describe what you need... (e.g., 'Create a Python REST API with authentication')",
            height=80,
            label_visibility="collapsed",
            key="main_input"
        )

        # Generate button
        send_clicked = st.button(
            "üöÄ Generate Optimized Prompt",
            type="primary",
            use_container_width=True,
            key="generate_btn"
        )

    # ==================== INSIGHTS COLUMN ====================
    with insights_col:
        st.markdown("### üìä Insights")

        # Render insights panel based on last result
        if st.session_state.last_result:
            result = st.session_state.last_result
            render_insights_panel(
                domain=result.get('domain', 'general'),
                task_type=result.get('task_type', 'general'),
                quality_score=result.get('quality_score', 85),
                metrics=result.get('metrics'),
                suggestions=result.get('suggestions', []),
                show_content=True
            )
        else:
            render_insights_panel(show_content=False)

            # Quick tips
            st.markdown("**üí° How it works:**")
            st.markdown("1. Describe your task")
            st.markdown("2. LUKTHAN analyzes context")
            st.markdown("3. Get optimized prompt")
            st.markdown("4. Copy to ChatGPT/Claude")

# ==================== PROCESS INPUT ====================

if send_clicked and user_input.strip():
    # Add user message to history
    user_message = {
        'role': 'user',
        'content': user_input,
        'timestamp': datetime.now().strftime("%H:%M"),
        'file_name': st.session_state.uploaded_file_name,
        'file_type': st.session_state.uploaded_file_type
    }
    st.session_state.chat_history.append(user_message)

    # Process with AI Agent
    with st.spinner("üß† Generating optimized prompt..."):
        try:
            from core.prompt_agent import PromptAgent

            # Get settings
            domain_override = None
            if 'domain_setting' in st.session_state:
                domain_map = {
                    "üî¨ Research": "research",
                    "üíª Coding": "coding",
                    "üìä Data Science": "data_science",
                    "üåê General": "general"
                }
                selected = st.session_state.domain_setting
                if selected != "üîÆ Auto Detect":
                    domain_override = domain_map.get(selected)

            agent = PromptAgent()
            result = agent.process_input_sync(
                user_input=user_input,
                file_content=st.session_state.uploaded_file_content,
                file_type=st.session_state.uploaded_file_type
            )

            # Calculate metrics
            base_score = result.quality_score
            metrics = {
                "Clarity": min(100, base_score + 5),
                "Specificity": max(0, base_score - 3),
                "Structure": min(100, base_score + 2),
                "Completeness": max(0, base_score - 5)
            }

            # Add agent response
            agent_message = {
                'role': 'agent',
                'prompt': result.optimized_prompt,
                'domain': result.domain,
                'task_type': result.task_type,
                'quality_score': result.quality_score,
                'suggestions': result.suggestions,
                'timestamp': datetime.now().strftime("%H:%M")
            }
            st.session_state.chat_history.append(agent_message)

            # Store for insights
            st.session_state.last_result = {
                'domain': result.domain,
                'task_type': result.task_type,
                'quality_score': result.quality_score,
                'metrics': metrics,
                'suggestions': result.suggestions
            }

            # Clear file uploads
            st.session_state.uploaded_file_content = None
            st.session_state.uploaded_file_type = None
            st.session_state.uploaded_file_name = None

        except Exception as e:
            st.error(f"Error: {str(e)}")
            st.session_state.chat_history.append({
                'role': 'agent',
                'prompt': f"Error: {str(e)}\n\nPlease try again.",
                'domain': 'error',
                'task_type': 'error',
                'quality_score': 0,
                'suggestions': ["Try rephrasing your request"],
                'timestamp': datetime.now().strftime("%H:%M")
            })

    st.rerun()

# Handle regeneration
if hasattr(st.session_state, 'regenerate_last') and st.session_state.regenerate_last:
    st.session_state.regenerate_last = False
    for i in range(len(st.session_state.chat_history) - 1, -1, -1):
        if st.session_state.chat_history[i]['role'] == 'user':
            if i + 1 < len(st.session_state.chat_history):
                st.session_state.chat_history.pop(i + 1)
            st.session_state.pending_input = st.session_state.chat_history[i]['content']
            break
    st.rerun()

# ==================== FOOTER ====================

st.markdown("---")
st.caption("üß† **LUKTHAN** ‚Äî Structured prompts for serious research and code.")
